% Lecture 32 -  Memory Management Issues
% CprE 308
% April 2, 2014

# Intro

## Overview
Ideal World (for the programmer):

 - I'm the only process in the world
 - I have a huge amount of memory at my disposal

Real World

 - Many processes in the system
 - Not enough memory for them all

**Goal:** Present the ideal world view to the programmer, yet implement it on a real system

## Today's topics
Memory Management Issues:

 - Page frame allocation
 - Thrashing
 - Working set
 - Belady's Anomaly

Speeding up Page Table Lookups

 - Page table caches

# Memory Management Issues

## Memory Management Issues
 - Fetch policy - when to fetch pages into memory?
 - Placement policy - where to plae pages?
 - Replacement policy
 - \structure{Page Frame Allocation}

## Page Frame Allocation: Global vs. Local
**Global Allocation**

 - All processes compete for pages from a single pool
    - Don't have to desired how many pages go to different processes
    - High priority processes might get pages of lower priority processes

\pause

**Local Allocation**

 - each process has its own private pool of page frames
    - Equal allocation: processes get equal number of page frames
    - Proportional allocation: number of page frames proportional to size of virtual memory used

## Thrashing
 - Consider a system that has exactly two page frames:
    - process A has a page in frame 1
    - process B has a page in frame 2
    - process B faults; the page in frame 1 is removed
    - process A resumes execution and faults again; the page in frame 2 is removed
    - ...
 - The process spends most of the time waiting for disk reads
 - A program causing page faults every few instruction is said to be *thrashing*

## Working Set
<!---
w(k,t):
 - t: time instance
 - k: all pages used by k most recent memory references
Perhaps draw example on board?
1 2 1 1 3 2 1 4 5 1 1 1 1 3 1
calculate w(k,t) at time t=15
Show graph from page 210

Basic idea of algorithm: find page not in working set
 - WSClock algorithm

See book for more details
-->
 - \structure{Locality of reference:}
    - During a phase of execution, a process references only a relatively small fraction of its pages.
 - \structure{Definition:} the **Working Set** of a process is the set of referenced pages in the last $k$ memory references
 - Each process should have the working set in memory
    - Keep track of working set
    - Make sure the process' working set is in memory before letting the process run -> loading the pages before letting it run -> prepaging
    - Reduce the page fault rate, avoid thrashing this way

## Belady's anomaly
<!---
Idea: Lots of page frames isn't always better.
-->
![](img/belady.png)

# TLB 

## Performance
 - Address translation is done on every memory reference
 - Maybe twice per instruction
    - Instruction fetch
    - Fetch Memory operand
 - Translation better be fast!

## Where do Page Tables Go?
 - Registers
    - Fast translation
    - Can be used for small page tables (a few 10s of entries)
 - Context Switch is quite expensive: reload new page translations into registers


## Where do Page Tables Go?
 - Memory
    - Slow translation
    - Large tables can be stored
 - The page-table base register (PTBR) holds a pointer to the page table location
 - **Page-table length register** (PRLR) indicates size of the page table
 - Context Switch is quick - only need to change this register
 - Currently used in most systems, because of the large page tables
 - Problem: Cannot afford a memory access for each translation
    - 4 memory in total for an instruction involving memory operands!

## Faster Translations
 - Translation Lookaside Buffer (=Page Table Cache)
 - Frequent translations found in the high-speed cache - TLB hit
 - Rest will go to slower-speed memory - (TLB miss)

## Associative Register
Associative registers - parallel search

![](img/assoc.png)

Address translation ($A',A''$)
 - If $A'$ is in associative register, get frame # out
 - Otherwise get frame # from page table in memory
    - This is done by the OS, and takes some time

## TLBs - Translation Lookaside Buffers
<!---
This might be generated by process with loop spanning pages 19,20,21, with data in 129,130; 140.  Stack on 860/861.
-->
![](img/tlb.png)

 - Speeds up paging by caching recent address translations
 - Typically small size - a few 10s of entries
 - TLB Hit rates are very important for performance

## TLB = Associative Memory
Given a virtual address, check all the TLB locations simultaneously for a hit

 - requires expensive hardware

Usually between 64-1024 entries

Multiple address spaces

 - TLB contains translations for only one address space at a time
    - TLB flushed on every context switch
 - Contains translations for all address spaces simultaneously
    - Each entry should have an identifier for the address space

## TLB impact on AAT
<!---
Also assume no page fault
-->
 - Associative Lookup = $\epsilon$ time unit
 - Assume memory cycle time is $m$ microsecond
 - Hit ratio - percentage of times that a page number is found in the associative registiers
    - hit ratio related to number of associative registers
 - Hit ratio = $\alpha$
 - Average Access Time (AAT):
\begin{equation*}
AAT = \alpha (m + \epsilon) + (1 - \alpha)(2m + \epsilon)
    = 2m + \epsilon - \alpha m
\end{equation*}

## Impact of TLB on Performance
TLB hit ratio = percent of time a trnalsation can be found in the TLB

**Example:**

 - 80 percent hit ratio
 - TLB search = 20 nsec
 - Memory access = 100 nsec
 - Effective memory access time = ?

\pause

**Answer:**
0.8(120) + 0.2(220) = 140 nsec

# Page Table Size

## Topics
 - Handling large page tables
    - Multi-level page tables
    - Inverted page table
 - `vfork()` and Copy-on-Write
 - Page Size

## TODO
